{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import time\n",
    "from time import localtime, strftime\n",
    "\n",
    "import epics\n",
    "import h5py\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from optlnls.math import get_fwhm\n",
    "from optlnls.plot import plot_xy\n",
    "from scipy.ndimage import rotate\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "from hddcmpylib.constants import MncConstants\n",
    "from hddcmpylib.move import MoveKyma, MoveBraggEnergy\n",
    "\n",
    "BeamlineConstants = MncConstants()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of necessary PVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DvfPrefix = 'MNC:A:BASLER02'\n",
    "\n",
    "pv_DVF_image = DvfPrefix + ':image1:ArrayData'\n",
    "pv_DVF_exp_time = DvfPrefix + ':cam1:AcquireTime'\n",
    "pv_DVF_acq_period = DvfPrefix + ':cam1:AcquirePeriod'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undulator emission related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_harmonics_given_energy(energy_points, min_energy=1.870,\n",
    "                                max_energy=3.600, initial_harmonic=3,\n",
    "                                print_points=False,\n",
    "                                only_max_harmonic=False):\n",
    "    \"\"\"Find harmonic for given energy.\n",
    "\n",
    "    Args:\n",
    "        energy_points (list of floats): Energy values [keV]\n",
    "        min_energy (float, optional): Minimum energy E1. Defaults to 1.870.\n",
    "        max_energy (float, optional): Max energy E1. Defaults to 3.600.\n",
    "        initial_harmonic (int, optional): Initial harmonic. Defaults to 3.\n",
    "        print_points (int, optional): print points. Defaults to False.\n",
    "        only_max_harmonic (bool, optional): only max harmonic. Defaults to\n",
    "         False.\n",
    "\n",
    "    Returns:\n",
    "        list: List of points with [energy, harmonic].\n",
    "    \"\"\"\n",
    "    scan_points = []\n",
    "    for energy in energy_points:\n",
    "\n",
    "        if only_max_harmonic:\n",
    "            k = initial_harmonic\n",
    "            while True:\n",
    "                if ((energy / k >= min_energy) & (energy / k <= max_energy)):\n",
    "                    max_harmonic = k\n",
    "                elif (energy / k < min_energy):\n",
    "                    break\n",
    "                k += 2\n",
    "            scan_points.append([energy, max_harmonic])\n",
    "\n",
    "            if print_points:\n",
    "                print(scan_points[-1])\n",
    "\n",
    "        else:\n",
    "            k = initial_harmonic\n",
    "            while True:\n",
    "                if ((energy / k >= min_energy) & (energy / k <= max_energy)):\n",
    "                    scan_points.append([energy, k])\n",
    "                    if print_points:\n",
    "                        print(scan_points[-1])\n",
    "                elif (energy / k < min_energy):\n",
    "                    break\n",
    "                k += 2\n",
    "    return scan_points\n",
    "\n",
    "def poly_any_degree(x, coefficients):\n",
    "    \"\"\"Generate a polynom with given coefficients.\n",
    "\n",
    "    Args:\n",
    "        x (1d numpy array): Points to evaluate polynom\n",
    "        coefficients (1d numpy array): polynom's coefficients,\n",
    "        ascending order.\n",
    "\n",
    "    Returns:\n",
    "        1d numpy array: Polynom calculated in points x.\n",
    "    \"\"\"\n",
    "    return np.polyval(coefficients[::-1], x)\n",
    "\n",
    "def _search_phase(x, *args):\n",
    "    energy = args[0]\n",
    "    coeffs = args[1]\n",
    "    return np.abs(poly_any_degree(x, coeffs) - energy)\n",
    "\n",
    "def get_phase_from_energy_h1(energy, coefficients, bounds=None):\n",
    "    \"\"\"Get phase for given H1 energy.\n",
    "\n",
    "    Args:\n",
    "        energy (float): Energy in keV\n",
    "        coefficients (1d numpy array): E1 vs phase coeefficients\n",
    "        bounds (2 element float list, optional): Bounds for phase search.\n",
    "            Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        float: Phase for fiven energy\n",
    "    \"\"\"\n",
    "    if bounds is None:\n",
    "        bounds = [0, 11]\n",
    "\n",
    "    args = (energy, coefficients)\n",
    "    res = minimize_scalar(_search_phase,\n",
    "        args=args, bounds=bounds, method='bounded')\n",
    "    return res.x\n",
    "\n",
    "def get_manaca_poly_coefficients():\n",
    "    \"\"\"Manaca E1 vs phase curve coefficients.\n",
    "\n",
    "       Updated on 2022-06-10.\n",
    "\n",
    "    Returns:\n",
    "        1d numpy array: Polynom coefficients.\n",
    "    \"\"\"\n",
    "    poly_coeffs = np.array([1.87967e+00,\n",
    "                            7.27222e-06,\n",
    "                            2.07199e-02,\n",
    "                            -5.43703e-04,\n",
    "                            4.02718e-04,\n",
    "                            -1.07571e-04,\n",
    "                            1.92051e-05,\n",
    "                            -1.76339e-06,\n",
    "                            5.52816e-08])\n",
    "\n",
    "    return poly_coeffs\n",
    "\n",
    "def get_phase_from_energy(energy_value=12.00, harmonic_number=5, verbose=True):\n",
    "    \"\"\"Find phase for given harmonic and energy.\n",
    "\n",
    "    Args:\n",
    "        energy_value (float, optional): Energy value [keV]. Defaults to 12.00.\n",
    "        harmonic_number (int, optional): Harmonic. Defaults to 5.\n",
    "        verbose (int, optional): Print info. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        float: Phase\n",
    "    \"\"\"\n",
    "    # Find possible harmonics\n",
    "    harmonics = find_harmonics_given_energy(energy_points=[energy_value],\n",
    "                                            only_max_harmonic=False)\n",
    "\n",
    "    harmonics = np.array(harmonics)\n",
    "    harmonics = harmonics[:, 1].astype(int)\n",
    "\n",
    "    if harmonic_number in harmonics:\n",
    "\n",
    "        energy1 = energy_value / harmonic_number\n",
    "        poly_coefficients = get_manaca_poly_coefficients()\n",
    "        phase = get_phase_from_energy_h1(energy1, poly_coefficients,\n",
    "            bounds=[0, 10])\n",
    "        phase = round(phase, 3)\n",
    "\n",
    "        if verbose:\n",
    "            print('phase value is:', phase)\n",
    "            print('energy:', energy_value, 'keV')\n",
    "            print('h =', harmonic_number)\n",
    "            print('fundamental energy =', round(energy1, 3))\n",
    "\n",
    "    else:\n",
    "        if verbose:\n",
    "            print('harmonic h =', harmonic_number,\n",
    "                'is not valid for this energy.')\n",
    "            print('please choose a valid harmonic number')\n",
    "        phase = np.nan\n",
    "\n",
    "    if verbose:\n",
    "        print('\\n')\n",
    "        print('possible harmonics for this energy are:')\n",
    "        for h in harmonics:\n",
    "            print('h =', h)\n",
    "\n",
    "    return phase\n",
    "\n",
    "def get_current_value():\n",
    "    \"\"\"Get storage ring current.\n",
    "\n",
    "    Returns:\n",
    "        float: current value.\n",
    "    \"\"\"\n",
    "    return epics.caget('SI-Glob:AP-CurrInfo:Current-Mon')\n",
    "\n",
    "def put_undulator(value):\n",
    "    \"\"\"Set undulator phase and start movement.\n",
    "\n",
    "    Args:\n",
    "        value (float): Phase value.\n",
    "    \"\"\"\n",
    "    epics.caput(pv_und_phase_write, value, wait=True)\n",
    "    time.sleep(0.5)\n",
    "    epics.caput(pv_und_phase_start, 3, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Fundamental Harmonic vs Undulator Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6560/605883321.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create a list of phase values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mphase_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m51\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# the calibration is converted into a 8th degree fitted polynomial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpoly_coefficients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_manaca_poly_coefficients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# create a list of phase values\n",
    "phase_values = np.linspace(0, 10.5, 51)\n",
    "\n",
    "# the calibration is converted into a 8th degree fitted polynomial\n",
    "poly_coefficients = get_manaca_poly_coefficients()\n",
    "\n",
    "# use the coefficients to generate the calibrated function\n",
    "fundamental_energies = poly_any_degree(phase_values, poly_coefficients)\n",
    "\n",
    "plot_xy(phase_values, fundamental_energies,\n",
    "       xlabel='Undulator Phase [mm]', ylabel='Fundamental Energy [keV]',\n",
    "       title='Undulator tunning calibration on 2022-06-10')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image acquisition and processing related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_max_value(image_pv, shape=None, binning=None, plot_image=False):\n",
    "    \"\"\"Get max image max value.\n",
    "\n",
    "    Args:\n",
    "        image_pv (str): Image pv\n",
    "        shape (list of ints, optional): Image shape. Defaults to None.\n",
    "        binning (list of ints, optional): Average image. Defaults to None.\n",
    "        plot_image (bool, optional): Plot image. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        float: max value\n",
    "    \"\"\"\n",
    "    if binning is None:\n",
    "        binning = [1, 1]\n",
    "    if shape is None:\n",
    "        shape = [1024, 1280, 1]\n",
    "\n",
    "    # acquire image\n",
    "    img = np.array(epics.caget(image_pv))  # get image from pv\n",
    "    img = img.reshape(shape[0], shape[1], shape[2])  # reshape array\n",
    "    img = img[:, :, 0]  # get the RGB channel\n",
    "\n",
    "    # bin image to avoid saturating noise\n",
    "    if binning != [1, 1]:\n",
    "        img = bin_matrix(img, binning[0], binning[1])\n",
    "\n",
    "    # get maximum value\n",
    "    img_max = np.max(img)\n",
    "\n",
    "    if plot_image:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        im = ax.imshow(img, origin=\"lower\")\n",
    "        fig.colorbar(im, ax=ax)\n",
    "        plt.show()\n",
    "\n",
    "    return img_max\n",
    "\n",
    "def adjust_exposure_time(\n",
    "    image_pv,\n",
    "    exp_time_pv,\n",
    "    saturation=256,\n",
    "    threshold=None,\n",
    "    shape=None,\n",
    "    binning=None,\n",
    "    exp_time_max=1,\n",
    "    debug=False,\n",
    "):\n",
    "    \"\"\"Adjust exposure time.\n",
    "\n",
    "    Args:\n",
    "        image_pv (str): Image pv\n",
    "        exp_time_pv (str): Exposure time pv name\n",
    "        saturation (int, optional): Saturation value. Defaults to 256 for 8b.\n",
    "        threshold (list of floats, optional): Max and minimum desired values\n",
    "         for image max value. Defaults to None.\n",
    "        shape (list of ints, optional): Image shape. Defaults to None.\n",
    "        binning (list of ints, optional): Average image. Defaults to None.\n",
    "        exp_time_max (float, optional): Max exp time [ms]. Defaults to 1.\n",
    "        debug (Boolean, optional): Print steps. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        float: camera integration time [s]\n",
    "    \"\"\"\n",
    "    if shape is None:\n",
    "        shape = [1024, 1280, 1]\n",
    "    if binning is None:\n",
    "        binning = [1, 1]\n",
    "    if threshold is None:\n",
    "        threshold = [0.75, 0.85]\n",
    "\n",
    "    # import epics\n",
    "    img_max = get_image_max_value(image_pv, shape, binning)\n",
    "\n",
    "    # check if exposure time is ok\n",
    "    exp_time_is_bad = (img_max < threshold[0] * saturation) or (\n",
    "        img_max > threshold[1] * saturation\n",
    "    )\n",
    "    exp_time = float(epics.caget(exp_time_pv))\n",
    "\n",
    "    # optimize exposure time\n",
    "    if exp_time_is_bad:\n",
    "        print(\"exposure time is bad. trying to optimize... \")\n",
    "\n",
    "        if debug:\n",
    "            print(\"\\t exposure time is \", round(exp_time, 3))\n",
    "\n",
    "        trial_number = 0\n",
    "        while exp_time_is_bad:\n",
    "            trial_number += 1\n",
    "            if debug:\n",
    "                print(\"\\t trial number is \", trial_number)\n",
    "\n",
    "            # avoid infinite loops\n",
    "            if trial_number > 20:\n",
    "                if debug:\n",
    "                    print(\"\\t failed to optimize exposure time\")\n",
    "                break\n",
    "\n",
    "            img_max = get_image_max_value(image_pv, shape, binning)\n",
    "            if debug:\n",
    "                print(\"\\t image maximum is\", round(img_max, 1))\n",
    "\n",
    "            # if is saturated, divide time by 2\n",
    "            if img_max >= threshold[1] * saturation:\n",
    "                exp_time = round(exp_time / 2, 4)\n",
    "                epics.caput(exp_time_pv, exp_time, wait=True)\n",
    "                if debug:\n",
    "                    print(\n",
    "                        \"\\t image saturated. changing exp time to \", exp_time\n",
    "                    )\n",
    "                time.sleep(2 * exp_time)\n",
    "\n",
    "            # if exposure time is too low, estimate the ideal value\n",
    "            elif img_max <= threshold[0] * saturation:\n",
    "                if img_max >= saturation * 0.05:\n",
    "                    # increase_factor = np.mean(threshold)*saturation / img_max\n",
    "                    increase_factor = 1.2\n",
    "                else:\n",
    "                    increase_factor = 2.0\n",
    "\n",
    "                exp_time = round(exp_time * increase_factor, 4)\n",
    "\n",
    "                # only increase if it is less than maximum allowed time\n",
    "                if exp_time <= exp_time_max:\n",
    "                    epics.caput(exp_time_pv, exp_time, wait=True)\n",
    "                    if debug:\n",
    "                        print(\n",
    "                            \"\\t image underexposed. changing exp time to \",\n",
    "                            exp_time,\n",
    "                        )\n",
    "                    time.sleep(2 * exp_time)\n",
    "\n",
    "                else:\n",
    "                    str_ = \"\\t calculated exposition time larger than allowed.\"\n",
    "                    str_ += \" Optimization failed.\"\n",
    "                    print(str_)\n",
    "                    epics.caput(exp_time_pv, exp_time_max, wait=True)\n",
    "                    time.sleep(2 * exp_time_max)\n",
    "                    break\n",
    "\n",
    "            # else, exposure time is ok\n",
    "            else:\n",
    "                exp_time_is_bad = False\n",
    "                print(\n",
    "                    \"\\t exp time set to {0:.3f} . max value = {1:.1f}\".format(\n",
    "                        exp_time, img_max\n",
    "                    )\n",
    "                    + \" optimization was successful. \\n\"\n",
    "                )\n",
    "        return exp_time\n",
    "\n",
    "    else:\n",
    "        print(\"   no need to optimize exposure time\")\n",
    "        return exp_time\n",
    "\n",
    "def bin_matrix(matrix, binning_y, binning_x):\n",
    "    \"\"\"Bin matrix (average matrix).\n",
    "\n",
    "    Args:\n",
    "        matrix (2d numpy array): Image matrix\n",
    "        binning_y (int): Nr pts to bin vertical\n",
    "        binning_x (int): Nr pts to bin horizontal\n",
    "\n",
    "    Returns:\n",
    "        2d numpy array: Binned matrix\n",
    "    \"\"\"\n",
    "    yn, xn = matrix.shape\n",
    "\n",
    "    if (xn % binning_x != 0) or (yn % binning_y != 0):\n",
    "        print(\n",
    "            \"array of shape ({0} x {1}) cannot be binned by factor ({2},{3})\".format(\n",
    "                yn, xn, binning_y, binning_x\n",
    "            )\n",
    "        )\n",
    "        return matrix\n",
    "\n",
    "    else:\n",
    "        xn = int(xn / binning_x)\n",
    "        yn = int(yn / binning_y)\n",
    "\n",
    "        matrix_binned = np.zeros((yn, xn), dtype=float)\n",
    "\n",
    "        count_y = 0\n",
    "        for iy in range(yn):\n",
    "            count_x = 0\n",
    "            for ix in range(xn):\n",
    "                matrix_binned[iy, ix] = np.sum(\n",
    "                    matrix[\n",
    "                        count_y : count_y + binning_y,\n",
    "                        count_x : count_x + binning_x,\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                count_x += binning_x\n",
    "            count_y += binning_y\n",
    "\n",
    "        matrix_binned /= binning_x * binning_y\n",
    "\n",
    "        if 0:\n",
    "            fig, ax = plt.subplots(figsize=(12, 4), ncols=2)\n",
    "            im0 = ax[0].imshow(matrix, origin=\"lower\")\n",
    "            im1 = ax[1].imshow(matrix_binned, origin=\"lower\")\n",
    "            fig.colorbar(im0, ax=ax[0])\n",
    "            fig.colorbar(im1, ax=ax[1])\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "        return matrix_binned\n",
    "\n",
    "def acquire_image(\n",
    "    image_pv, shape=None, binning=None, plot_image=False\n",
    "):\n",
    "    \"\"\"Acquire image.\n",
    "\n",
    "    Args:\n",
    "        image_pv (str): Image pv\n",
    "        shape (list of ints, optional): Image shape. Defaults to None.\n",
    "        binning (list of ints, optional): Average image. Defaults to None.\n",
    "        plot_image (bool, optional): Plot image. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        2d numpy array: Array with image data\n",
    "    \"\"\"\n",
    "    if shape is None:\n",
    "        shape = (1024, 1280)\n",
    "    if binning is None:\n",
    "        binning = (1, 1)\n",
    "\n",
    "    img = np.array(epics.caget(image_pv))\n",
    "    img = img.reshape(shape)\n",
    "\n",
    "    if binning != (1, 1):\n",
    "        img = bin_matrix(img, binning[0], binning[1])\n",
    "\n",
    "    if plot_image:\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        im = ax.imshow(img, origin=\"lower\", cmap=\"jet\")\n",
    "        fig.colorbar(im, ax=ax)\n",
    "        plt.show()\n",
    "\n",
    "    return img\n",
    "\n",
    "def get_centroid(img, x=0, y=0):\n",
    "    \"\"\"Get image centroid.\n",
    "\n",
    "    Args:\n",
    "        img (2d numpy array): Image\n",
    "        x (int, optional): Image points. Defaults to 0.\n",
    "        y (int, optional): Image points. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        tuple of ints: Centroid position (y0, x0)\n",
    "    \"\"\"\n",
    "    shape = img.shape\n",
    "    if x == 0:\n",
    "        x = np.arange(0, shape[1])\n",
    "    if y == 0:\n",
    "        y = np.arange(0, shape[0])\n",
    "\n",
    "    ix = np.sum(img, axis=0)\n",
    "    iy = np.sum(img, axis=1)\n",
    "\n",
    "    x_mean = int(np.round(np.average(x, weights=ix)))\n",
    "    y_mean = int(np.round(np.average(y, weights=iy)))\n",
    "    return (y_mean, x_mean)\n",
    "\n",
    "def get_vertical_cut(img, x=0, nx=20, binning=(1, 1), plot_cut=False):\n",
    "    \"\"\"Get vertical cut.\n",
    "\n",
    "    Args:\n",
    "        img (2d numpy array): Image\n",
    "        x (int, optional): x position to do cut. Defaults to 0.\n",
    "        nx (int, optional): nr of y points to get. Defaults to 20.\n",
    "        binning (tuple, optional): Bin matrix. Defaults to (1, 1).\n",
    "        plot_cut (bool, optional): Plot cut. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        1d numpy array: cut\n",
    "    \"\"\"\n",
    "    if binning != (1, 1):\n",
    "        img = bin_matrix(img, binning[0], binning[1])\n",
    "\n",
    "    if nx == 1:\n",
    "        xmin = int(x)\n",
    "\n",
    "    elif nx > 1:\n",
    "        xmin = int(x - nx / 2)\n",
    "\n",
    "    xmax = int(xmin + nx)\n",
    "\n",
    "    cut = np.sum(img[:, xmin:xmax], axis=1) / nx\n",
    "\n",
    "    if plot_cut:\n",
    "        plt.figure()\n",
    "        plt.plot(cut)\n",
    "        plt.show()\n",
    "\n",
    "    return cut\n",
    "\n",
    "def define_ROI(\n",
    "    pv_prefix=\"MNC:A:BASLER02\",\n",
    "    ROI_shape=(400, 400),\n",
    "    ROI_start=(0, 0),\n",
    "    ROI_binning=(1, 1),\n",
    "):\n",
    "    \"\"\"Define region of interest (ROI).\n",
    "\n",
    "    Args:\n",
    "        pv_prefix (str, optional): pv prefix. Defaults to \"MNC:A:BASLER02\".\n",
    "        ROI_shape (tuple, optional): _description_. Defaults to (400, 400).\n",
    "        ROI_start (tuple, optional): _description_. Defaults to (0, 0).\n",
    "        ROI_binning (tuple, optional): _description_. Defaults to (1, 1).\n",
    "    \"\"\"\n",
    "    pv_image = pv_prefix + \":image1:ArrayData\"\n",
    "\n",
    "    # enable ROI\n",
    "    epics.caput(pv_prefix + \":ROI1:EnableCallbacks\", 1, wait=True)\n",
    "    epics.caput(pv_prefix + \":image1:NDArrayPort\", \"ROI1\", wait=True)\n",
    "\n",
    "    # set ROI\n",
    "    epics.caput(pv_prefix + \":ROI1:MinX\", ROI_start[1], wait=True)\n",
    "    epics.caput(pv_prefix + \":ROI1:MinY\", ROI_start[0], wait=True)\n",
    "\n",
    "    epics.caput(pv_prefix + \":ROI1:SizeX\", ROI_shape[1], wait=True)\n",
    "    epics.caput(pv_prefix + \":ROI1:SizeY\", ROI_shape[0], wait=True)\n",
    "\n",
    "    epics.caput(pv_prefix + \":ROI1:BinX\", ROI_binning[1], wait=True)\n",
    "    epics.caput(pv_prefix + \":ROI1:BinY\", ROI_binning[0], wait=True)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "def initialize_hdf5(h5_filename):\n",
    "    \"\"\"Initialize a h5 file.\n",
    "\n",
    "    Args:\n",
    "        h5_filename (str): File name\n",
    "    \"\"\"\n",
    "    with h5py.File(h5_filename, \"w\") as f:\n",
    "        f.attrs[\"begin time\"] = time.strftime(\n",
    "            \"%Y-%m-%d %H:%M:%S\", time.localtime()\n",
    "        )\n",
    "        f.create_group(\"images\")\n",
    "        f.create_group(\"vertical_cuts\")\n",
    "\n",
    "def end_hdf5(h5_filename):\n",
    "    \"\"\"Finish a h5 file.\n",
    "\n",
    "    Args:\n",
    "        h5_filename (str): File name\n",
    "    \"\"\"\n",
    "    with h5py.File(h5_filename, \"a\") as f:\n",
    "        f.attrs[\"end time\"] = time.strftime(\n",
    "            \"%Y-%m-%d %H:%M:%S\", time.localtime()\n",
    "        )\n",
    "\n",
    "def create_group(h5_filename, group_name, group_attributes):\n",
    "    \"\"\"Create a group in h5 file.\n",
    "\n",
    "    Args:\n",
    "        h5_filename (str): File name\n",
    "        group_name (str): Group name\n",
    "        group_attributes (dict): Group attributes\n",
    "    \"\"\"\n",
    "    with h5py.File(h5_filename, \"a\") as f:\n",
    "        group_images = f[\"images\"].create_group(group_name)\n",
    "        group_cuts = f[\"vertical_cuts\"].create_group(group_name)\n",
    "\n",
    "        for i in range(len(group_attributes)):\n",
    "            group_images.attrs[group_attributes[i][0]] = group_attributes[i][1]\n",
    "            group_cuts.attrs[group_attributes[i][0]] = group_attributes[i][1]\n",
    "\n",
    "def append_image_to_hdf5(\n",
    "    h5_filename, group_name, dataset_name, image, attributes\n",
    "):\n",
    "    \"\"\"Add image to h5 file.\n",
    "\n",
    "    Args:\n",
    "        h5_filename (str): File name\n",
    "        group_name (str): Group name\n",
    "        dataset_name (_type_): _description_\n",
    "        image (_type_): _description_\n",
    "        attributes (_type_): _description_\n",
    "    \"\"\"\n",
    "    with h5py.File(h5_filename, \"a\") as f:\n",
    "        group = f[\"images/\" + group_name]\n",
    "        dset = group.create_dataset(\n",
    "            dataset_name, data=image, compression=\"gzip\"\n",
    "        )\n",
    "\n",
    "        for i in range(len(attributes)):\n",
    "            dset.attrs[attributes[i][0]] = attributes[i][1]\n",
    "\n",
    "def append_cut_to_hdf5(h5_filename, group_name, dataset_name, cut, attributes):\n",
    "    \"\"\"Append cut to h5 file.\n",
    "\n",
    "    Args:\n",
    "        h5_filename (str): File name\n",
    "        group_name (str): Group name\n",
    "        dataset_name (_type_): _description_\n",
    "        cut (_type_): _description_\n",
    "        attributes (_type_): _description_\n",
    "    \"\"\"\n",
    "    with h5py.File(h5_filename, \"a\") as f:\n",
    "        group = f[\"vertical_cuts/\" + group_name]\n",
    "        dset = group.create_dataset(dataset_name, data=cut, compression=\"gzip\")\n",
    "\n",
    "        for i in range(len(attributes)):\n",
    "            dset.attrs[attributes[i][0]] = attributes[i][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi_shape = (1024,1280)\n",
    "# roi_start = (0,0)\n",
    "\n",
    "roi_shape = (400, 400)\n",
    "roi_start = (32, 860)\n",
    "\n",
    "define_ROI(\n",
    "    pv_prefix=DvfPrefix,\n",
    "    ROI_shape=roi_shape,\n",
    "    ROI_start=roi_start,\n",
    "    ROI_binning=(1, 1),\n",
    ")\n",
    "\n",
    "img = np.array(epics.caget(pv_DVF_image))\n",
    "img = img.reshape(roi_shape)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "im = ax.imshow(img, cmap=\"viridis\", origin=\"lower\")\n",
    "fig.colorbar(im, ax=ax)\n",
    "ax.vlines(x=200, ymin=0, ymax=400, color=\"w\", linestyle=\"--\", alpha=0.3)\n",
    "ax.hlines(y=200, xmin=0, xmax=400, color=\"w\", linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "# np.savetxt('/home/ABTLUS/xafs/data/2021-03-27/DVF3_dark_field_39p8mA_010ms_no_led.txt', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Scan Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### scan points: \n",
    "### [0]: central energy in keV\n",
    "### [1]: undulator phase in mm \n",
    "### [2]: harmonic number\n",
    "### [3]: delta energy in keV (scan from -de/2 to de/2) \n",
    "### [4]: number of points in energy\n",
    "\n",
    "scan_points = [[ 5.672, 0.000, 3, 0.2, 15],\n",
    "               [ 9.454, 0.000, 5, 0.2, 15],\n",
    "               [13.235, 0.000, 7, 0.2, 15],\n",
    "              ]\n",
    "\n",
    "# phase = 0.0\n",
    "# harmonic = 5\n",
    "\n",
    "# energy_points_e7 = np.linspace(13.235 - de, 13.235 + de, 11)\n",
    "# energy_points_e5 = np.linspace(9.454 - de, 9.454 + de, 11)\n",
    "# energy_points_e3 = np.linspace(5.672 - de, 5.672 + de, 11)\n",
    "\n",
    "# if harmonic == 3:\n",
    "#     energy_points = energy_points_e3\n",
    "# elif harmonic == 5:\n",
    "#     energy_points = energy_points_e5\n",
    "# elif harmonic == 7:\n",
    "#     energy_points = energy_points_e7\n",
    "# else:\n",
    "#     print('Invalid harmonic')\n",
    "\n",
    "# scan_points = []\n",
    "# phase = 0\n",
    "# for i, energy in enumerate(energy_points):\n",
    "#     point_to_scan = [energy, phase, harmonic]\n",
    "#     scan_points.append(point_to_scan)\n",
    "#     print(point_to_scan)\n",
    "\n",
    "# print(\"total number of points to scan is\", len(scan_points))\n",
    "\n",
    "# shuffle points\n",
    "# random.shuffle(scan_points)\n",
    "# for point in scan_points:\n",
    "#     print(point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.672, 0.0, 3, 0.2, 15], [9.454, 0.0, 5, 0.2, 15], [13.235, 0.0, 7, 0.2, 15]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Scan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time_str = time.strftime(\"%Y-%m-%d_%Hh%Mm%Ss\", time.localtime())\n",
    "h5_filename  = '/home/ABTLUS/sergio.lordano/data/2024-02-20/'\n",
    "h5_filename += 'MNC_UndAlign_NoBump' + time_str + '.h5'\n",
    "\n",
    "initialize_hdf5(h5_filename)\n",
    "\n",
    "img_shape = [roi_shape[0], roi_shape[1], 1]\n",
    "\n",
    "integral_values = []\n",
    "energy_values = []\n",
    "\n",
    "for i in range(len(scan_points)):\n",
    "    \n",
    "    ### get setpoints for each scan point\n",
    "    DCM_value, UND_value, harmonic, de, ne = scan_points[i]\n",
    "    delta_energy_array = np.linspace(-de/2, de/2, ne)\n",
    "    integral_values_i = np.zeros(ne)\n",
    "    energy_values.append(DCM_value + delta_energy_array) \n",
    "    \n",
    "    ### Move DCM and Undulator to central positions \n",
    "    if(1):    \n",
    "        \n",
    "        print('\\n')\n",
    "        print('Moving... step {0} out of {1}'.format(i+1, len(scan_points)))\n",
    "        print('DCM Energy = {0:.3f} keV at harmonic {1}'.format(DCM_value, harmonic))\n",
    "        print('UND Phase = {0:.3f} mm'.format(UND_value))\n",
    "\n",
    "        ### Move Undulator\n",
    "        MoveKyma(prefix=UndPrefix, pos=UND_value, vel=0.5, time_ext=5, verbose=0, wait=True)\n",
    "        time.sleep(1)\n",
    "\n",
    "        ### MoveDCM\n",
    "        MoveBraggEnergy(prefix=DcmPrefix, energy=DCM_value, vel=1e-4, d2=d2, verbose=0, wait=True)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        print('Finished moving to central energy!')\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    ### Adjust camera exposure time to avoid saturation\n",
    "    if(1):\n",
    "        print('Adjusting exposure time for central energy...')\n",
    "\n",
    "        group_name = '{0:.03d}_E_{1:.3f}keV_z_{2:.3f}mm'.format(i, scan_points[i][0], UND_value)\n",
    "\n",
    "        group_attributes = []\n",
    "        group_attributes.append(['DCM Central Energy', DCM_value])\n",
    "        group_attributes.append(['Undulator Phase', UND_value])\n",
    "        group_attributes.append(['Harmonic', harmonic])\n",
    "\n",
    "        create_group(h5_filename, group_name, group_attributes)\n",
    "\n",
    "        exp_time = adjust_exposure_time(pv_DVF_image, pv_DVF_exp_time, saturation=2**8,\n",
    "                                        threshold=[0.3, 0.5], shape=img_shape,\n",
    "                                        binning=[4,4], exp_time_max=1.1, debug=0)\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    ### scan energies around central energy\n",
    "    if(1):        \n",
    "        for j, delta_energy in enumerate(delta_energy_array):\n",
    "\n",
    "            DCM_value_j = DCM_value + delta_energy\n",
    "            \n",
    "            ### MoveDCM\n",
    "            MoveBraggEnergy(prefix=DcmPrefix, energy=DCM_value_j, vel=1e-4, d2=d2, verbose=0, wait=True)\n",
    "            time.sleep(0.5)\n",
    "\n",
    "            print('     acquiring...')\n",
    "            acquisition_time = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime())\n",
    "            current = get_current_value()\n",
    "\n",
    "            ### acquire image\n",
    "            img = acquire_image(pv_DVF_image, roi_shape)\n",
    "            img_sum = np.sum(img)\n",
    "            integral_values_i[j] = img_sum\n",
    "\n",
    "            ### get centroid\n",
    "            centroid_y, centroid_x = get_centroid(img)\n",
    "\n",
    "\n",
    "            img_attributes = []\n",
    "            #img_attributes.append(['Undulator Phase', UND_value])\n",
    "            img_attributes.append(['DCM Energy', DCM_value_j])\n",
    "            img_attributes.append(['Integral', img_sum])\n",
    "            img_attributes.append(['Current', current])\n",
    "            img_attributes.append(['CentroidX', centroid_x])\n",
    "            img_attributes.append(['CentroidY', centroid_y])\n",
    "            img_attributes.append(['Acquisition Time', acquisition_time])\n",
    "            img_attributes.append(['Exposure Time', exp_time])\n",
    "\n",
    "            dataset_name = '{0:03d}_E_{1:.3f}keV'.format(j, DCM_value_new)\n",
    "            append_image_to_hdf5(h5_filename, group_name, dataset_name, img, img_attributes)\n",
    "\n",
    "        integral_values.append(integral_values_i)\n",
    "        \n",
    "        if(i == len(scan_points) - 1):\n",
    "            end_hdf5(h5_filename)\n",
    "\n",
    "\n",
    "print(\"FINISHED!!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(scan_points)):\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(energy_values[i], integral_values[i])\n",
    "    plt.xlabel('Energy [keV]')\n",
    "    plt.ylabel('Spectral Flux [a.u.]')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aquire_image(pv_DVF2_image, shape=(1024,1280), filename=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = np.array(epics.caget(pv_DVF2_image))\n",
    "\n",
    "# img = img.reshape((1024,1280))\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(img, origin='lower')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust_exposure_time(pv_DVF_image, pv_DVF_exp_time, saturation=2**16,\n",
    "#                          threshold=[0.7, 0.9], shape=[1024, 1280, 1],\n",
    "#                          binning=[4,4], exp_time_max=1.1, debug=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epics.caget('MNC:A:BASLER02:cam1:ArraySizeX_RBV')\n",
    "# epics.caget('MNC:A:BASLER02:cam1:ArraySizeY_RBV')\n",
    "# epics.caget('MNC:A:BASLER02:cam1:ArraySizeZ_RBV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_pv = DvfPrefix + ':image1:ArrayData'\n",
    "# exp_time_pv = DvfPrefix + ':cam1:AcquireTime'\n",
    "\n",
    "# shape = [roi_shape[0], roi_shape[1], 1]\n",
    "\n",
    "# adjust_exposure_time(image_pv, exp_time_pv, saturation=2**16,\n",
    "#                      threshold=[0.4, 0.7], shape=shape,\n",
    "#                      binning=[1,1], exp_time_max=1, debug=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = acquire_image(pv_DVF2_image, roi_shape, binning=(1,1), plot_image=1)\n",
    "\n",
    "# centroid_y, centroid_x = get_centroid(img)\n",
    "# print(centroid_y, centroid_x)\n",
    "# cut_binning = 4\n",
    "# cut = get_vertical_cut(img, x=centroid_x, nx=20, binning=(cut_binning,1), plot_cut=1)\n",
    "# fwhm_pts = get_fwhm(np.arange(0, int(roi_shape[0]/cut_binning)), cut)\n",
    "# fwhm = fwhm_pts[0] * cut_binning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
